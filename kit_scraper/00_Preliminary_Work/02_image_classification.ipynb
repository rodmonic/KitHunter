{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_dominant_colors(image_path, mask_path, k=3):\n",
    "    # Load the image and the mask\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load mask as grayscale\n",
    "    \n",
    "    # Ensure the mask is binary (0 and 255 values)\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Reshape the image to a 2D array of pixels (excluding masked areas)\n",
    "    pixels = masked_image.reshape(-1, 3)\n",
    "    \n",
    "    # Remove black pixels (masked-out areas where RGB = [0, 0, 0])\n",
    "    pixels = pixels[np.any(pixels != [0, 0, 0], axis=1)]\n",
    "    \n",
    "    # Convert pixels to float32 for KMeans input (required by OpenCV)\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria for K-means (iterations and accuracy)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Run KMeans clustering on the pixels\n",
    "    _, labels, centers = cv2.kmeans(\n",
    "        pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "    \n",
    "    # Convert the centers (dominant colors) back to integer type (RGB)\n",
    "    dominant_colors = np.uint8(centers)\n",
    "    \n",
    "    return dominant_colors\n",
    "\n",
    "# Example usage:\n",
    "image_path = './downloads/Kit_left_arm_2.png'\n",
    "mask_path = './downloads/Kit_left_arm_mask.png'  # Path to your mask image\n",
    "\n",
    "dominant_colors = detect_dominant_colors(image_path, mask_path, k=3)\n",
    "\n",
    "print(\"Dominant colors in the masked area are:\", dominant_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def fill_in_background_color(file):\n",
    "    # Define the new background color (R, G, B)\n",
    "    background_color = (255,255,255)\n",
    "    \n",
    "    # Open the existing image\n",
    "    existing_image = Image.open(file)\n",
    "\n",
    "    # Get the size of the existing image\n",
    "    width, height = existing_image.size\n",
    "\n",
    "    # Create a new image with the same size and the background color\n",
    "    background = Image.new('RGB', (width, height), background_color)\n",
    "\n",
    "    # Paste the existing image onto the background\n",
    "    # We use the alpha channel if the existing image has transparency\n",
    "    background.paste(existing_image, (0, 0), existing_image.convert('RGBA'))\n",
    "\n",
    "    # Save the new image\n",
    "    background.save(file)\n",
    "\n",
    "fill_in_background_color('./downloads/Kit_right_arm_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image_path):\n",
    "    # Load image in grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    \n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred_image, 100, 200)\n",
    "    \n",
    "    return edges\n",
    "\n",
    "# Example usage\n",
    "edges = detect_edges(image_path)\n",
    "\n",
    "# Display edges\n",
    "cv2.imshow(\"Edges\", edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_image_white_to_black_transparent_to_white(image_path, save_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)  # Load with alpha channel if exists\n",
    "\n",
    "    # Check if image has 4 channels (RGBA)\n",
    "    if image.shape[2] == 4:\n",
    "        # Split into BGR and Alpha channels\n",
    "        bgr_image = image[:, :, :3]  # BGR part of the image\n",
    "        alpha_channel = image[:, :, 3]  # Alpha channel\n",
    "\n",
    "        # Create a mask for fully transparent pixels (alpha == 0)\n",
    "        transparent_mask = alpha_channel == 0\n",
    "\n",
    "        # Set transparent pixels to white in the BGR image\n",
    "        bgr_image[transparent_mask] = [255, 255, 255]\n",
    "\n",
    "        # Now check for white pixels in the BGR image (RGB [255, 255, 255])\n",
    "        white_mask = np.all(bgr_image == [255, 255, 255], axis=-1)\n",
    "\n",
    "        # Set white pixels to black (RGB [0, 0, 0])\n",
    "        bgr_image[white_mask] = [0, 0, 0]\n",
    "\n",
    "        # Merge the processed BGR image with the original alpha channel (if needed)\n",
    "        final_image = np.dstack((bgr_image, alpha_channel))\n",
    "\n",
    "    else:\n",
    "        # If there is no alpha channel, treat it as a simple BGR image\n",
    "        bgr_image = image\n",
    "\n",
    "        # Find white pixels in the BGR image (RGB [255, 255, 255])\n",
    "        white_mask = np.all(bgr_image == [255, 255, 255], axis=-1)\n",
    "\n",
    "        # Set white pixels to black (RGB [0, 0, 0])\n",
    "        bgr_image[white_mask] = [0, 0, 0]\n",
    "\n",
    "        # Set the image to white where no alpha (if no transparency is involved, this step is skipped)\n",
    "        final_image = bgr_image\n",
    "\n",
    "    # Save the processed image\n",
    "    cv2.imwrite(save_path, final_image)\n",
    "\n",
    "    return final_image\n",
    "\n",
    "# Example usage:\n",
    "image_path = './downloads/Kit_right_arm.png'\n",
    "save_path = './downloads/Kit_right_arm_mask.png'\n",
    "\n",
    "processed_image = process_image_white_to_black_transparent_to_white(image_path, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def detect_dominant_colors_cv2(image_path, mask_path, k=3):\n",
    "    # Load the image and the mask\n",
    "    image = cv2.imread(image_path)  # Image is loaded in BGR format\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load mask as grayscale\n",
    "    \n",
    "    # Ensure the mask is binary (0 and 255 values)\n",
    "    _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Convert BGR to RGB for color consistency\n",
    "    masked_image_rgb = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape the image to a 2D array of pixels (excluding masked areas)\n",
    "    pixels = masked_image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Remove black pixels (masked-out areas where RGB = [0, 0, 0])\n",
    "    pixels = pixels[np.any(pixels != [0, 0, 0], axis=1)]\n",
    "    \n",
    "    # Check if there are enough pixels left for K-means\n",
    "    if len(pixels) == 0:\n",
    "        raise ValueError(\"No valid pixels found after applying the mask.\")\n",
    "    \n",
    "    if len(pixels) < k:\n",
    "        raise ValueError(f\"Not enough pixels for {k} clusters. Found {len(pixels)} pixels.\")\n",
    "\n",
    "    # Convert pixels to float32 for KMeans input (required by OpenCV)\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria for K-means (iterations and accuracy)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Run KMeans clustering on the pixels\n",
    "    _, labels, centers = cv2.kmeans(\n",
    "        pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "    \n",
    "    # Convert the centers (dominant colors) back to integer type (RGB)\n",
    "    dominant_colors = np.uint8(centers)\n",
    "    \n",
    "    return dominant_colors, masked_image_rgb\n",
    "\n",
    "image_path = './downloads/Kit_left_arm_2.png'\n",
    "mask_path = './downloads/Kit_left_arm_mask.png'  # Path to your mask image\n",
    "\n",
    "try:\n",
    "    dominant_colors, masked_image_rgb = detect_dominant_colors_cv2(image_path, mask_path, k=3)\n",
    "\n",
    "    # Display the masked image to visually check if it's correct\n",
    "    plot_image(masked_image_rgb, \"Masked Image\")\n",
    "\n",
    "    print(\"Dominant colors in the masked area are:\", dominant_colors)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Function to display the dominant colors\n",
    "def plot_dominant_colors(dominant_colors):\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.axis(\"off\")\n",
    "    color_rects = np.zeros((50, 50 * len(dominant_colors), 3), dtype=np.uint8)\n",
    "    for i, color in enumerate(dominant_colors):\n",
    "        color_rects[:, i * 50:(i + 1) * 50] = color\n",
    "    plt.imshow(color_rects)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the dominant colors\n",
    "plot_dominant_colors(dominant_colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
